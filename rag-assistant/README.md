# RAG Assistant — Qdrant + MCP + OpenAI

## Описание

RAG‑ассистент (Retrieval‑Augmented Generation), который:

- хранит документы в **Qdrant** (векторное хранилище),
- принимает PDF через форму,
- режет их на чанки и индексирует,
- предоставляет LLM инструмент для поиска по базе знаний через MCP‑сервер.

Подходит как база для внутренних ассистентов по документации, регламентам, FAQ и др.

---

## Используемые интеграции

- **Qdrant** — векторное хранилище документов
- **OpenAI Embeddings** — генерация эмбеддингов для поиска
- **MCP Server** — инструмент для LLM, который ходит в n8n за контекстом
- **Form Trigger** — загрузка PDF пользователем

---

## Как запустить

1. Импортируйте `workflow.json` в n8n.
2. Настройте подключение к вашему инстансу Qdrant (URL, API key, коллекция).
3. Пропишите API‑ключ OpenAI.
4. Поднимите MCP‑сервер, который обращается к этому workflow как к инструменту.
5. Загрузите PDF через форму и задайте вопрос ассистенту — он должен отвечать, опираясь на найденные фрагменты документов.
